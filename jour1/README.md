# Jour 1 - Fondamentaux de Kafka

## üéØ Objectifs de la journ√©e
- D√©couvrir l'architecture Kafka (cluster, brokers, topics, partitions)
- Comprendre les concepts fondamentaux par l'exploration
- Identifier les notions cl√©s de Kafka
- Observer le partitionnement et les offsets
- Cr√©er et configurer des topics avec diff√©rents param√®tres
- Comprendre le m√©canisme des segments et leur impact sur le stockage
- Ma√Ætriser les politiques de r√©tention et la log compaction
- Comprendre la r√©plication et la haute disponibilit√©
- Tester la r√©silience du cluster face aux pannes
- Identifier les conditions d'une partition offline

---

## Exercice 1 - Explorer le Cluster Kafka

**Dur√©e:** 45 minutes

### Objectifs
- D√©marrer un cluster Kafka en mode KRaft (sans Zookeeper)
- Explorer l'interface Kafka UI
- D√©couvrir par observation les concepts Kafka
- Identifier et lister les notions fondamentales

### Approche p√©dagogique
Cet exercice utilise une **approche par d√©couverte**. Les participants explorent librement l'interface Kafka UI et identifient eux-m√™mes les concepts cl√©s. Cette m√©thode favorise l'apprentissage actif et la m√©morisation.

### Notions d√©couvertes
√Ä travers cet exercice, les participants vont d√©couvrir:
- **Architecture**: Cluster, Broker, KRaft
- **Organisation des donn√©es**: Topic, Partition, Replication Factor
- **Structure des messages**: Message, Key, Value, Header, Timestamp
- **Positionnement**: Offset
- **Sch√©mas**: Schema Registry, JSON Schema
- **Types de donn√©es**: String, JSON, Binary

### Contenu fourni
- Docker Compose avec Kafka en mode KRaft
- Kafka UI pour l'exploration visuelle
- Schema Registry pour la gestion des sch√©mas
- 7 topics pr√©-provisionn√©s avec diff√©rents types de donn√©es:
  - `events` - Messages texte simples (3 partitions)
  - `users` - JSON sans cl√© (2 partitions)
  - `orders` - JSON avec cl√©s (4 partitions)
  - `logs` - Logs texte (1 partition)
  - `images` - Donn√©es binaires (2 partitions)
  - `transactions` - JSON avec cl√©s et headers (2 partitions)
  - `products` - JSON avec JSON Schema enregistr√© (2 partitions)

### Livrable
Les participants doivent produire une **liste de 10-15 notions/concepts** identifi√©s avec:
- Le nom de la notion
- O√π ils l'ont trouv√©e dans l'UI
- Leur hypoth√®se sur ce que c'est

### D√©roulement
1. **30 min** - Exploration libre de Kafka UI
2. **15 min** - Mise en commun et explication des notions identifi√©es

### Acc√®s √† l'exercice
üìÅ Dossier: `jour1/exercice1-explorer-cluster/`

Voir le README de l'exercice pour les instructions d√©taill√©es.

---

## Exercice 2 - Topics et Segments

**Dur√©e:** 60 minutes

### Objectifs
- Cr√©er des topics avec diff√©rentes configurations
- Comprendre le m√©canisme de segmentation des logs
- Explorer le syst√®me de fichiers Kafka
- Analyser les fichiers de segments (.log, .index, .timeindex)
- Configurer les politiques de r√©tention (temps, taille, combin√©e)
- Comprendre et utiliser la log compaction

### Approche p√©dagogique
Cet exercice est **pratique et orient√© ligne de commande**. Les participants cr√©ent des topics avec diff√©rents param√®tres de segmentation, produisent des messages, et explorent directement le syst√®me de fichiers Kafka pour observer comment les segments sont cr√©√©s et g√©r√©s.

### Notions approfondies
√Ä travers cet exercice, les participants vont approfondir:
- **Configuration de topics**: partitions, segment.bytes, segment.ms
- **Segments**: .log (donn√©es), .index (index d'offset), .timeindex (index de temps)
- **Stockage**: organisation physique dans /var/lib/kafka/data/
- **Analyse**: kafka-dump-log pour inspecter les segments
- **R√©tention**:
  - Bas√©e sur le temps (retention.ms)
  - Bas√©e sur la taille (retention.bytes)
  - Politique combin√©e (temps ET taille)
- **Log Compaction**:
  - cleanup.policy=compact
  - R√©tention par cl√© (derni√®re valeur uniquement)
  - Tombstone records (suppression logique)
  - Cas d'usage: √©tat utilisateur, cache, CDC

### Contenu de l'exercice
L'exercice est divis√© en 8 parties:
1. **Topic avec configuration par d√©faut** - Observer la configuration standard
2. **Topic avec 10 partitions** - Impact du partitionnement sur le stockage
3. **Topic avec segments de petite taille** - Forcer la cr√©ation de multiples segments (segment.bytes=500)
4. **Production de messages** - Via Kafka UI pour remplir les topics
5. **Exploration du syst√®me de fichiers** - Acc√®s shell pour observer les segments
6. **Politiques de r√©tention**:
   - R√©tention bas√©e sur le temps (1 minute)
   - R√©tention bas√©e sur la taille (2KB)
   - R√©tention combin√©e
7. **Log Compaction**:
   - Configuration d'un topic compact√©
   - Test avec des cl√©s dupliqu√©es
   - Utilisation des tombstones pour supprimer des cl√©s
8. **Analyse et comparaison** - Tableau r√©capitulatif de toutes les configurations

### Livrables
Les participants doivent:
- Cr√©er 8 topics avec des configurations diff√©rentes
- Explorer le syst√®me de fichiers et identifier les segments
- Analyser le contenu des segments avec kafka-dump-log
- Comprendre les diff√©rentes politiques de r√©tention et leurs cas d'usage
- Expliquer la diff√©rence entre suppression et compaction
- Produire un tableau comparatif des configurations test√©es

### D√©roulement
1. **10 min** - Cr√©ation des topics et configuration
2. **15 min** - Production de messages et exploration filesystem
3. **15 min** - Analyse des segments avec kafka-dump-log
4. **15 min** - Test des politiques de r√©tention
5. **10 min** - Compaction et tombstones
6. **5 min** - Synth√®se et comparaison

### Acc√®s √† l'exercice
üìÅ Dossier: `jour1/exercice2-topics-segments/`

Voir le README de l'exercice pour les instructions d√©taill√©es.

---

## Exercice 3 - R√©plication et R√©silience

**Dur√©e:** 75 minutes

### Objectifs
- Comprendre le m√©canisme de r√©plication dans Kafka
- Observer la distribution des replicas entre les brokers
- Identifier les r√¥les Leader et Follower
- Analyser les m√©tadonn√©es d'un topic (ISR, Leader, Replicas)
- Tester la r√©silience du cluster en arr√™tant des brokers
- Mettre une partition offline et comprendre les conditions

### Approche p√©dagogique
Cet exercice est **exp√©rimental et interactif**. Les participants travaillent avec un cluster multi-brokers (3 n≈ìuds) et simulent des pannes pour observer le comportement de Kafka en conditions d√©grad√©es. L'approche "chaos engineering" permet de comprendre les garanties et limites de la r√©plication.

### Notions approfondies
√Ä travers cet exercice, les participants vont approfondir:
- **Architecture multi-brokers**: Cluster de 3 n≈ìuds (2 controllers + 3 brokers)
- **R√©plication**:
  - Replication Factor (RF)
  - Leader et Followers
  - Synchronisation des replicas
- **Haute disponibilit√©**:
  - ISR (In-Sync Replicas)
  - min.insync.replicas
  - Leader election
- **R√©silience**:
  - Comportement avec 1 broker down
  - Comportement avec 2 brokers down
  - Conditions d'une partition offline
- **Durabilit√©**:
  - Impact de `acks=all`
  - Trade-off disponibilit√© vs durabilit√©

### Contenu de l'exercice
L'exercice est divis√© en 6 parties:
1. **Cr√©ation d'un topic avec r√©plication** - RF=3, 4 partitions, observer Leader/Replicas/ISR
2. **Production et r√©plication** - Produire des messages et v√©rifier la r√©plication physique
3. **Test de r√©silience: 1 broker down** - Arr√™ter kafka-3, observer le rebalancing
4. **Mettre une partition offline** - Arr√™ter 2 brokers simultan√©ment pour perdre le quorum
5. **Exp√©rimentations avanc√©es** - Tester min.insync.replicas=3, controller down
6. **Synth√®se et analyse** - Tableau r√©capitulatif des sc√©narios test√©s

### Livrables
Les participants doivent:
- Cr√©er un topic avec RF=3 et analyser sa distribution
- Expliquer la diff√©rence entre Replicas et ISR
- Identifier le Leader de chaque partition
- Simuler des pannes et observer les √©lections de leader
- Mettre une partition compl√®tement offline (Leader: none)
- Comprendre l'impact de min.insync.replicas sur la disponibilit√©
- Produire un tableau comparatif des sc√©narios de panne

### D√©roulement
1. **15 min** - Cr√©ation du topic et analyse des m√©tadonn√©es
2. **15 min** - Production et v√©rification de la r√©plication
3. **15 min** - Test avec 1 broker down
4. **15 min** - Sc√©nario partition offline (2 brokers down)
5. **10 min** - Exp√©rimentations avanc√©es (min.insync.replicas)
6. **5 min** - Synth√®se et questions de compr√©hension

### Acc√®s √† l'exercice
üìÅ Dossier: `jour1/exercice3-replication-resilience/`

Voir le README de l'exercice pour les instructions d√©taill√©es.

---

## üìù QCM - Validation des Connaissances

**Dur√©e:** 10 minutes + 15 minutes de correction

Apr√®s avoir compl√©t√© les 3 exercices, un QCM de 5 questions permet de valider la compr√©hension des concepts fondamentaux:
- Partitions
- Offsets
- Segments
- Politiques de r√©tention
- Log compaction

---

## üìö Ressources Compl√©mentaires

### Documentation
- [Kafka Documentation Officielle](https://kafka.apache.org/documentation/)
- [KRaft Mode](https://kafka.apache.org/documentation/#kraft)

### Commandes Kafka Essentielles

#### Lister les topics
```bash
docker exec kafka kafka-topics --bootstrap-server localhost:9092 --list
```

#### D√©crire un topic
```bash
docker exec kafka kafka-topics --bootstrap-server localhost:9092 --describe --topic orders
```

#### Consommer des messages
```bash
docker exec kafka kafka-console-consumer \
  --bootstrap-server localhost:9092 \
  --topic orders \
  --from-beginning \
  --property print.key=true \
  --property print.partition=true \
  --property print.offset=true
```

#### Cr√©er un topic
```bash
docker exec kafka kafka-topics --create \
  --bootstrap-server localhost:9092 \
  --topic mon-topic \
  --partitions 3 \
  --replication-factor 1
```

---

## üìù Notes pour le Formateur

### Points cl√©s √† aborder apr√®s l'exercice 1

**Architecture Kafka**
- Le cluster et ses composants
- Le r√¥le du broker
- KRaft vs Zookeeper (√©volution)

**Topics et Partitions**
- Le topic comme canal logique
- Le partitionnement pour la scalabilit√©
- L'ordre garanti par partition

**Messages**
- Structure: Key, Value, Headers, Timestamp
- Le r√¥le de la cl√© dans le partitionnement
- Les headers pour les m√©tadonn√©es

**Offsets**
- Position unique par partition
- Utilis√© par les consumers pour tracker leur progression
- S√©quentiel et croissant

**Schema Registry**
- Gestion centralis√©e des sch√©mas
- √âvolution des sch√©mas
- Compatibilit√©

### Points cl√©s √† aborder apr√®s l'exercice 2

**Segments et Stockage**
- Les segments comme unit√©s de stockage physique
- Fichiers .log, .index, .timeindex
- Segment actif vs segments ferm√©s
- Impact du param√®tre segment.bytes

**Politiques de R√©tention**
- R√©tention bas√©e sur le temps (retention.ms)
  - Cas d'usage: logs d'application, √©v√©nements temporaires
- R√©tention bas√©e sur la taille (retention.bytes)
  - Cas d'usage: limitation de l'espace disque
- Politique combin√©e (temps ET taille)
  - La premi√®re condition atteinte d√©clenche la suppression

**Log Compaction**
- Diff√©rence avec la suppression (delete)
- R√©tention de la derni√®re valeur par cl√©
- Tombstone records (cl√© avec valeur null) pour supprimer
- Cas d'usage:
  - √âtat utilisateur (user profiles)
  - Cache distribu√©
  - Change Data Capture (CDC)
  - Configuration management

**Comparaison Suppression vs Compaction**
| Aspect | Suppression (delete) | Compaction (compact) |
|--------|---------------------|----------------------|
| Politique | retention.ms / retention.bytes | cleanup.policy=compact |
| Conservation | Tout pendant la p√©riode | Derni√®re valeur par cl√© |
| Cas d'usage | Logs, √©v√©nements temporaires | √âtats, cache, CDC |
| Garanties | Fen√™tre temporelle fixe | Toujours la derni√®re valeur |

### Points cl√©s √† aborder apr√®s l'exercice 3

**R√©plication**
- Replication Factor (RF) - nombre de copies d'une partition
- Leader - broker responsable des lectures/√©critures
- Followers - r√©pliquent les donn√©es du leader
- Garantie de durabilit√© avec RF > 1

**ISR (In-Sync Replicas)**
- Liste des replicas synchronis√©s avec le leader
- Un follower sort des ISR s'il prend trop de retard
- Critique pour la haute disponibilit√©
- Nombre d'ISR >= min.insync.replicas pour accepter les √©critures

**Leader Election**
- Automatique en cas de panne du leader actuel
- Nouveau leader choisi parmi les ISR
- Transparent pour les clients (reconnexion automatique)
- Impact sur la latence pendant l'√©lection (~quelques secondes)

**min.insync.replicas**
- Nombre minimum de replicas in-sync requis pour une √©criture
- Utilis√© avec `acks=all` pour garantir la durabilit√©
- Exemple: RF=3, min.insync.replicas=2 ‚Üí tol√®re 1 broker down
- Trade-off: disponibilit√© vs durabilit√©

**Partition Offline**
- Se produit quand tous les ISR sont down
- Aucun leader disponible
- Les √©critures et lectures √©chouent sur cette partition
- R√©cup√©ration: red√©marrer au moins un broker des ISR

**Controller**
- Broker sp√©cial qui g√®re les m√©tadonn√©es du cluster
- En mode KRaft: quorum de controllers (haute disponibilit√©)
- Responsable des √©lections de leader
- G√®re l'ajout/suppression de brokers

**Cas d'usage r√©els**
| Sc√©nario | RF | min.insync.replicas | Tol√©rance panne | Cas d'usage |
|----------|----|--------------------|-----------------|-------------|
| Dev/Test | 1 | 1 | Aucune | Environnement non-critique |
| Production Standard | 3 | 2 | 1 broker | √âquilibre disponibilit√©/durabilit√© |
| Production Critique | 3 | 3 | Aucune (√©criture) | Donn√©es critiques, aucune perte acceptable |
| Multi-DC | 5+ | 3 | 2 brokers | Distribution g√©ographique |
