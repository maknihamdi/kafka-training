# Exercice 2 - Topics et Segments Kafka

## üéØ Objectifs
- Cr√©er des topics avec diff√©rentes configurations
- Comprendre le concept de partitions
- D√©couvrir les segments et leur gestion par Kafka
- Explorer le syst√®me de fichiers du broker
- Observer comment Kafka stocke physiquement les donn√©es

## ‚è±Ô∏è Dur√©e
60 minutes

## üìö Concepts Cl√©s

### Topics et Partitions
- Un topic est divis√© en partitions pour la scalabilit√©
- Chaque partition est un log ordonn√© et immuable
- Les partitions permettent le parall√©lisme

### Segments
- Chaque partition est divis√©e en segments (fichiers physiques)
- Un segment contient un ensemble de messages
- Kafka cr√©e un nouveau segment quand le segment actif atteint sa taille limite
- Configuration: `segment.bytes` (par d√©faut: 1GB)

### Fichiers de segment
Pour chaque segment, Kafka cr√©e 3 fichiers:
- `.log` - Les messages eux-m√™mes
- `.index` - Index des offsets
- `.timeindex` - Index des timestamps

## üöÄ Instructions

### 1. D√©marrer le Cluster

```bash
make start
```

Attendez 10-15 secondes que Kafka soit pr√™t.

### 2. Partie 1 - Topic Simple (Configuration par d√©faut)

#### Cr√©er un topic avec la configuration par d√©faut

```bash
docker exec kafka kafka-topics --create \
  --bootstrap-server localhost:9092 \
  --topic topic-default 
```

#### D√©crire le topic

```bash
docker exec kafka kafka-topics --describe \
  --bootstrap-server localhost:9092 \
  --topic topic-default
```

**Questions √† se poser:**
- Quelle est la configuration du topic?
- Combien de partitions?

#### Explorer le syst√®me de fichiers

```bash
# Ouvrir un shell dans le container
make shell

# Dans le shell du container:
ls -lah /var/lib/kafka/data/

# Trouver le dossier du topic
ls -lah /var/lib/kafka/data/topic-default-0/

# Examiner les fichiers de segment
ls -lh /var/lib/kafka/data/topic-default-0/*.log
ls -lh /var/lib/kafka/data/topic-default-0/*.index
```

**Observations:**
- Voyez-vous des fichiers `.log`, `.index`, `.timeindex`?
- Quelle est leur taille initiale?

### 3. Partie 2 - Topic avec Plusieurs Partitions

#### Cr√©er un topic avec 10 partitions

```bash
docker exec kafka kafka-topics --create \
  --bootstrap-server localhost:9092 \
  --topic topic-multipart \
  --partitions 10 
```

#### Explorer la structure

```bash
make shell

# Dans le shell:
ls -lah /var/lib/kafka/data/ | grep topic-multipart
```

**Questions:**
- Combien de dossiers voyez-vous pour ce topic?
- Comment sont-ils nomm√©s?
- Que contient chaque dossier?

### 4. Partie 3 - Topic avec Segment Personnalis√© (1MB)

Pour observer la cr√©ation de segments, on va cr√©er un topic avec des segments de petite taille.

#### Cr√©er un topic avec segment.bytes = 500

```bash
docker exec kafka kafka-topics --create \
  --bootstrap-server localhost:9092 \
  --topic topic-small-segments \
  --partitions 2 \
  --config segment.bytes=500
```

#### V√©rifier la configuration

```bash
docker exec kafka kafka-topics --describe \
  --bootstrap-server localhost:9092 \
  --topic topic-small-segments \
  --config segment.bytes
```

Ou plus complet:

```bash
docker exec kafka kafka-configs --describe \
  --bootstrap-server localhost:9092 \
  --entity-type topics \
  --entity-name topic-small-segments \
  --all
```

### 5. Partie 4 - Produire des Messages et Observer les Segments

#### Produire des messages via Kafka UI

1. Ouvrez Kafka UI: http://localhost:8080
2. Allez dans le topic `topic-small-segments`
3. Cliquez sur "Produce Message"
4. Produisez plusieurs messages (au moins 20-30)

**Exemple de message volumineux pour remplir rapidement:**

```json
{
  "id": 1,
  "data": "Lorem ipsum dolor sit amet, consectetur adipiscing elit. Sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat. Duis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur. Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia deserunt mollit anim id est laborum. Lorem ipsum dolor sit amet, consectetur adipiscing elit. Sed do eiusmod tempor incididunt ut labore et dolore magna aliqua."
}
```

**Astuce:** Variez le `id` et dupliquez le texte pour avoir des messages de ~1KB chacun.

#### Observer la cr√©ation de segments

Pendant et apr√®s la production de messages:

```bash
# Voir l'√©volution des fichiers
docker exec kafka watch -n 1 "ls -lh /var/lib/kafka/data/topic-small-segments-0/*.log"
```

Ou plus simple:

```bash
docker exec kafka ls -lh /var/lib/kafka/data/topic-small-segments-0/
```

**Questions:**
- Apr√®s combien de messages voyez-vous un nouveau fichier `.log` appara√Ætre?
- Quelle est la taille approximative des fichiers `.log`?
- Combien de fichiers `.log` avez-vous au total?

#### Examiner l'index

```bash
docker exec kafka kafka-dump-log \
  --files /var/lib/kafka/data/topic-small-segments-0/00000000000000000000.index \
  --print-data-log
```

**Questions:**
- √Ä quoi sert cet index?
- Comment Kafka trouve-t-il rapidement un message par offset?

### 6. Partie 6 - Politiques de R√©tention

Kafka offre plusieurs politiques pour g√©rer la r√©tention des donn√©es.

#### 6.1 R√©tention par Temps (Time-based Retention)

Cr√©er un topic avec r√©tention de 1 minute:

```bash
docker exec kafka kafka-topics --create \
  --bootstrap-server localhost:9092 \
  --topic topic-retention-time \
  --partitions 1 \
  --config segment.bytes=1000 \
  --config retention.ms=60000 \
  --config segment.ms=30000
```

**Tester la r√©tention:**

```bash
# Produire des messages
docker exec kafka bash -c "
for i in {1..50}; do
  echo 'Message '$i;
done | kafka-console-producer --bootstrap-server localhost:9092 --topic topic-retention-time
"

# Observer les segments
docker exec kafka ls -lh /var/lib/kafka/data/topic-retention-time-0/

# Attendre 2 minutes
sleep 120

# Observer √† nouveau (les anciens segments devraient √™tre supprim√©s)
docker exec kafka ls -lh /var/lib/kafka/data/topic-retention-time-0/
```

**Questions:**
- Les anciens segments ont-ils √©t√© supprim√©s apr√®s 1 minute?
- Combien de fichiers `.log` reste-t-il?
- Comment Kafka d√©termine-t-il quels segments supprimer?

#### 6.2 R√©tention par Taille (Size-based Retention)

Cr√©er un topic avec r√©tention limit√©e √† 2KB par partition:

```bash
docker exec kafka kafka-topics --create \
  --bootstrap-server localhost:9092 \
  --topic topic-retention-size \
  --partitions 1 \
  --config segment.bytes=500 \
  --config retention.bytes=2000
```

**Tester la r√©tention:**

```bash
# Produire suffisamment de messages pour d√©passer 2KB
docker exec kafka bash -c "
for i in {1..100}; do
  echo 'Message number '$i' with some padding to make it bigger';
done | kafka-console-producer --bootstrap-server localhost:9092 --topic topic-retention-size
"

# Observer les segments
docker exec kafka ls -lh /var/lib/kafka/data/topic-retention-size-0/

# Calculer la taille totale
docker exec kafka du -sh /var/lib/kafka/data/topic-retention-size-0/
```

**Questions:**
- Quelle est la taille totale des segments?
- Est-elle proche de 2KB (2000 bytes)?
- Que se passe-t-il quand on d√©passe cette limite?

#### 6.3 R√©tention Combin√©e (Temps ET Taille)

```bash
docker exec kafka kafka-topics --create \
  --bootstrap-server localhost:9092 \
  --topic topic-retention-combined \
  --partitions 1 \
  --config segment.bytes=500 \
  --config retention.ms=120000 \
  --config retention.bytes=3000
```

**La suppression se fait d√®s que l'une des conditions est atteinte!**

### 7. Partie 7 - Log Compaction

La compaction garde seulement le dernier message pour chaque cl√©.

#### 7.1 Cr√©er un Topic Compact√©

```bash
docker exec kafka kafka-topics --create \
  --bootstrap-server localhost:9092 \
  --topic topic-compacted \
  --partitions 1 \
  --config cleanup.policy=compact \
  --config segment.bytes=500 \
  --config min.cleanable.dirty.ratio=0.01 \
  --config segment.ms=10000
```

**Param√®tres de compaction:**
- `cleanup.policy=compact` - Active la compaction
- `min.cleanable.dirty.ratio=0.01` - Ratio minimal pour d√©clencher la compaction (1%)
- `segment.ms=10000` - Rotation de segment toutes les 10 secondes

#### 7.2 Tester la Compaction

```bash
# Produire des messages avec des cl√©s (plusieurs fois la m√™me cl√©)
docker exec kafka bash -c "
echo 'user1:Valeur initiale pour user1
user2:Valeur initiale pour user2
user3:Valeur initiale pour user3
user1:Mise √† jour 1 pour user1
user2:Mise √† jour 1 pour user2
user1:Mise √† jour 2 pour user1
user1:Valeur FINALE pour user1
user2:Valeur FINALE pour user2
user3:Valeur FINALE pour user3' | kafka-console-producer \
  --bootstrap-server localhost:9092 \
  --topic topic-compacted \
  --property 'parse.key=true' \
  --property 'key.separator=:'
"

# Consommer imm√©diatement - voir tous les messages
docker exec kafka kafka-console-consumer \
  --bootstrap-server localhost:9092 \
  --topic topic-compacted \
  --from-beginning \
  --property print.key=true \
  --property key.separator=: \
  --timeout-ms 5000
```

**Observer avant compaction:**

```bash
# Voir les segments
docker exec kafka ls -lh /var/lib/kafka/data/topic-compacted-0/

# Compter les messages dans le segment
docker exec kafka kafka-dump-log \
  --files /var/lib/kafka/data/topic-compacted-0/00000000000000000000.log \
  --print-data-log | grep -c "payload"
```

**Attendre la compaction (peut prendre quelques minutes):**

```bash
# Forcer la rotation des segments et attendre
sleep 30

# D√©clencher manuellement la compaction (optionnel)
# Note: La compaction se fait automatiquement en arri√®re-plan

# Consommer √† nouveau apr√®s compaction
docker exec kafka kafka-console-consumer \
  --bootstrap-server localhost:9092 \
  --topic topic-compacted \
  --from-beginning \
  --property print.key=true \
  --property key.separator=: \
  --timeout-ms 5000
```

**Questions:**
- Combien de messages voyez-vous pour chaque cl√© apr√®s compaction?
- Les anciennes valeurs sont-elles toujours pr√©sentes?
- Quelle est l'utilit√© de la compaction pour un syst√®me de cache distribu√©?

#### 7.3 Cas d'Usage de la Compaction

**Sc√©nario: √âtat des utilisateurs**

```bash
# Simuler des mises √† jour d'√©tat utilisateur
docker exec kafka bash -c "
echo 'user-123:{\"name\":\"Alice\",\"status\":\"active\",\"lastLogin\":\"2024-01-01\"}
user-456:{\"name\":\"Bob\",\"status\":\"active\",\"lastLogin\":\"2024-01-01\"}
user-123:{\"name\":\"Alice\",\"status\":\"active\",\"lastLogin\":\"2024-01-02\"}
user-789:{\"name\":\"Charlie\",\"status\":\"active\",\"lastLogin\":\"2024-01-02\"}
user-456:{\"name\":\"Bob\",\"status\":\"inactive\",\"lastLogin\":\"2024-01-03\"}
user-123:{\"name\":\"Alice\",\"status\":\"inactive\",\"lastLogin\":\"2024-01-04\"}' | \
kafka-console-producer \
  --bootstrap-server localhost:9092 \
  --topic topic-compacted \
  --property 'parse.key=true' \
  --property 'key.separator=:'
"
```

**Apr√®s compaction, vous obtenez un "snapshot" de l'√©tat actuel de chaque utilisateur!**

#### 7.4 Tombstone (Suppression de Cl√©)

Pour supprimer compl√®tement une cl√© du topic compact√©, envoyez une valeur `null`:

```bash
# Supprimer user-789
docker exec kafka bash -c "
echo 'user-789:' | kafka-console-producer \
  --bootstrap-server localhost:9092 \
  --topic topic-compacted \
  --property 'parse.key=true' \
  --property 'key.separator=:' \
  --property 'null.marker='
"
```

Apr√®s compaction, `user-789` dispara√Ætra compl√®tement du topic.

### 8. Exploration Bonus - Comparer les Topics

Cr√©ez un tableau comparatif de tous vos topics:

| Topic | Partitions | Segment Size | Retention Policy | Observations |
|-------|------------|--------------|------------------|--------------|
| topic-default | ... | ... | delete (default) | ... |
| topic-multipart | ... | ... | delete (default) | ... |
| topic-small-segments | ... | ... | delete (default) | ... |
| topic-retention-time | ... | ... | delete (1 min) | ... |
| topic-retention-size | ... | ... | delete (2KB) | ... |
| topic-compacted | ... | ... | compact | ... |

## üîß Commandes Utiles

### Gestion des Topics

```bash
# Lister tous les topics
docker exec kafka kafka-topics --bootstrap-server localhost:9092 --list

# Supprimer un topic
docker exec kafka kafka-topics --delete \
  --bootstrap-server localhost:9092 \
  --topic <topic-name>

# Modifier la configuration d'un topic
docker exec kafka kafka-configs --alter \
  --bootstrap-server localhost:9092 \
  --entity-type topics \
  --entity-name <topic-name> \
  --add-config segment.bytes=2097152
```

### Exploration du Syst√®me de Fichiers

```bash
# Ouvrir un shell
make shell

# Navigation dans les dossiers
cd /var/lib/kafka/data/
ls -lah

# Voir la taille des dossiers
du -sh /var/lib/kafka/data/*

# Compter les fichiers dans une partition
ls /var/lib/kafka/data/topic-small-segments-0/*.log | wc -l

# Voir les derni√®res modifications
ls -lt /var/lib/kafka/data/topic-small-segments-0/
```

### Production de Messages en Masse

Pour g√©n√©rer rapidement beaucoup de messages:

```bash
# Produire 1000 messages
docker exec kafka bash -c "
for i in {1..1000}; do
  echo '{\"id\":'\$i',\"message\":\"Message number '\$i' with some padding text to increase size\"}';
done | kafka-console-producer --bootstrap-server localhost:9092 --topic topic-small-segments
"
```

### Param√®tres Importants

- `segment.bytes` - Taille max d'un segment (d√©faut: 1GB)
- `segment.ms` - Temps max avant rotation (d√©faut: 7 jours)
- `retention.bytes` - Taille max de donn√©es √† conserver par partition
- `retention.ms` - Dur√©e de r√©tention des messages

### Pourquoi les Segments?

1. **Performance**: Lecture/√©criture optimis√©e sur des fichiers de taille raisonnable
2. **R√©tention**: Suppression facile des anciens segments
3. **Compaction**: Optimisation du stockage
4. **R√©plication**: Transfert plus efficace

## üêõ Troubleshooting

### Impossible de cr√©er un topic

```bash
# V√©rifier que Kafka est pr√™t
docker exec kafka kafka-broker-api-versions --bootstrap-server localhost:9092
```

### Les segments ne se cr√©ent pas

- V√©rifiez la taille des messages produits
- Assurez-vous que `segment.bytes` est assez petit
- Attendez quelques secondes apr√®s la production

### Cannot access /var/lib/kafka/data

```bash
# V√©rifier les permissions
docker exec kafka ls -la /var/lib/kafka/
```

## üìù Livrable

√Ä la fin de cet exercice, vous devez √™tre capable de:
- [ ] Cr√©er des topics avec diff√©rentes configurations
- [ ] Expliquer ce qu'est un segment et son r√¥le
- [ ] Naviguer dans le syst√®me de fichiers du broker
- [ ] Identifier les fichiers .log, .index, .timeindex
- [ ] Comprendre quand et pourquoi Kafka cr√©e de nouveaux segments
- [ ] Analyser le contenu d'un segment avec kafka-dump-log
- [ ] Configurer et comprendre les politiques de r√©tention (temps, taille, combin√©e)
- [ ] Expliquer le fonctionnement de la log compaction
- [ ] Identifier les cas d'usage appropri√©s pour la compaction vs suppression

## üìñ Pour Aller Plus Loin

### Compaction des Logs

Kafka peut aussi compacter les logs au lieu de les supprimer:

```bash
docker exec kafka kafka-topics --create \
  --bootstrap-server localhost:9092 \
  --topic topic-compacted \
  --partitions 1 \
  --replication-factor 1 \
  --config cleanup.policy=compact \
  --config segment.bytes=1048576
```

### Monitoring des Segments

```bash
# Voir les m√©triques JMX
docker exec kafka kafka-run-class kafka.tools.JmxTool \
  --object-name kafka.log:type=Log,name=Size,topic=topic-small-segments,partition=0 \
  --attributes Value
```