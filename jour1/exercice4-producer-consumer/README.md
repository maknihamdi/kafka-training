# Exercice 4 - Producer et Consumer Spring Boot

## ğŸ¯ Objectifs

- CrÃ©er un Producer Kafka avec Spring Boot
- CrÃ©er un Consumer Kafka standalone (sans consumer group)
- CrÃ©er un Consumer Kafka scalable (avec consumer group)
- Produire des messages via une API REST
- Comprendre la diffÃ©rence entre consommation standalone et avec consumer group
- Observer le partitionnement avec des clÃ©s
- Tester la consommation parallÃ¨le avec plusieurs instances

## ğŸ“‹ PrÃ©requis

- Docker et Docker Compose installÃ©s
- Java 17+ installÃ©
- Maven 3.6+ installÃ©
- IntelliJ IDEA (recommandÃ©) ou tout autre IDE Java
- Ports disponibles: 8081, 9092, 8080 (Kafka UI)

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   REST Client   â”‚â”€â”€â”€â”€â”€â”€â”€â”€>â”‚   Producer  â”‚â”€â”€â”€â”€â”€â”€â”€â”€>â”‚  Kafka Cluster  â”‚
â”‚  (Postman/curl) â”‚         â”‚  (port 8081)â”‚         â”‚  (port 9092)    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                                              â”‚
                                                              â”‚
                                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                                    â”‚                                                   â”‚
                                    v                                                   v
                            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                            â”‚    Consumer     â”‚                            â”‚  Scalable Consumer   â”‚
                            â”‚   (standalone)  â”‚                            â”‚  (consumer group)    â”‚
                            â”‚ Toutes partitionsâ”‚                           â”‚  Instance 1 & 2      â”‚
                            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Modules:**
- `producer` - Produit des messages via API REST
- `consumer` - Consumer standalone sans consumer group (assign manuel)
- `scalable-consumer` - Consumer avec consumer group (@KafkaListener)

**Topics:**
- `messages` - 4 partitions

---

## ğŸš€ Partie 1 - DÃ©marrage et Configuration

### 1.1 DÃ©marrer l'infrastructure Kafka

```bash
cd jour1/exercice4-producer-consumer
docker-compose up -d
```

VÃ©rifiez que Kafka est dÃ©marrÃ©:

```bash
docker ps
```

Vous devriez voir les conteneurs `kafka` et `kafka-ui`.

### 1.2 CrÃ©er le topic

```bash
docker exec kafka kafka-topics --create \
  --bootstrap-server localhost:9092 \
  --topic messages \
  --partitions 4 \
  --replication-factor 1
```

VÃ©rifiez:

```bash
docker exec kafka kafka-topics --describe \
  --bootstrap-server localhost:9092 \
  --topic messages
```

### 1.3 Compiler les modules

Depuis la racine de l'exercice 4:

```bash
mvn clean compile
```

Cela compile les 3 modules: `producer`, `consumer`, et `scalable-consumer`.

---

## ğŸ“¤ Partie 2 - Producer (API REST)

### 2.1 Structure du Producer

Le module `producer` contient:
- **ProducerApplication.java** - Point d'entrÃ©e Spring Boot
- **KafkaProducerConfig.java** - Configuration du producer (sÃ©rialisation JSON)
- **MessageProducerService.java** - Service pour envoyer des messages
- **MessageController.java** - API REST (port 8081)
- **Message.java** - ModÃ¨le de donnÃ©es

### 2.2 Lancer le Producer

**Via Maven:**
```bash
cd producer
mvn spring-boot:run
```

**Via IntelliJ:**
1. Ouvrez `producer/src/main/java/com/kafka/training/producer/ProducerApplication.java`
2. Clic droit â†’ Run 'ProducerApplication'

Le producer dÃ©marre sur le port **8081**.

### 2.3 Tester l'envoi de messages

**Envoyer un message simple:**

```bash
curl -X POST http://localhost:8081/api/messages/send \
  -H "Content-Type: application/json" \
  -d '{
    "topic": "messages",
    "key": "user-123",
    "content": "Hello Kafka!",
    "sender": "Alice"
  }'
```

**Envoyer un batch de messages:**

```bash
curl -X POST http://localhost:8081/api/messages/send-batch \
  -H "Content-Type: application/json" \
  -d '{
    "topic": "messages",
    "count": 20,
    "sender": "BatchSender"
  }'
```

### 2.4 Observer le partitionnement

**Messages avec la mÃªme clÃ©:**

```bash
for i in {1..5}; do
  curl -s -X POST http://localhost:8081/api/messages/send \
    -H "Content-Type: application/json" \
    -d "{
      \"topic\": \"messages\",
      \"key\": \"user-123\",
      \"content\": \"Message $i\",
      \"sender\": \"Alice\"
    }"
done
```

**Question:** Tous les messages vont-ils dans la mÃªme partition?
**RÃ©ponse:** Oui, car ils ont la mÃªme clÃ©.

**Messages avec des clÃ©s diffÃ©rentes:**

```bash
for i in {1..10}; do
  curl -s -X POST http://localhost:8081/api/messages/send \
    -H "Content-Type: application/json" \
    -d "{
      \"topic\": \"messages\",
      \"key\": \"user-$i\",
      \"content\": \"Message from user-$i\",
      \"sender\": \"User$i\"
    }"
done
```

**Question:** Comment sont distribuÃ©s les messages?
**RÃ©ponse:** Distribution basÃ©e sur le hash de la clÃ© entre les 4 partitions.

---

## ğŸ“¥ Partie 3 - Consumer Standalone (sans consumer group)

### 3.1 Structure du Consumer Standalone

Le module `consumer` contient:
- **ConsumerApplication.java** - Point d'entrÃ©e Spring Boot
- **KafkaConsumerConfig.java** - Configuration avec KafkaConsumer bean
- **MessageConsumerService.java** - Consommation via assign() (pas subscribe())
- **Message.java** - ModÃ¨le de donnÃ©es

### 3.2 CaractÃ©ristiques du Consumer Standalone

- âœ… Utilise `consumer.assign()` pour assigner manuellement les partitions
- âœ… **Pas de consumer group** (pas de group.id)
- âœ… Lit **toutes les partitions** du topic
- âœ… Loop infini avec `consumer.poll()`
- âœ… Pas de rebalancing
- âŒ Impossible de faire du load balancing avec d'autres instances

### 3.3 Lancer le Consumer Standalone

**Ouvrez un nouveau terminal** (le producer doit rester actif).

**Via Maven:**
```bash
cd consumer
mvn spring-boot:run
```

**Via IntelliJ:**
1. Ouvrez `consumer/src/main/java/com/kafka/training/consumer/ConsumerApplication.java`
2. Clic droit â†’ Run 'ConsumerApplication'

### 3.4 Observer la consommation

Le consumer affiche dans les logs:

```
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘ ğŸ“© Message reÃ§u - Standalone Mode                             â•‘
â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
â•‘ Topic        : messages
â•‘ Partition    : 2
â•‘ Offset       : 5
â•‘ Key          : user-123
â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
â•‘ Message      : Message{id='...', content='Hello Kafka!', ...}
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
```

### 3.5 Configuration dynamique des partitions

Dans `application.yml`:

```yaml
kafka:
  consumer:
    topic: messages
    partitions: 4  # Nombre de partitions Ã  consommer
```

Le consumer construit automatiquement la liste `[0, 1, 2, 3]` et les assigne toutes.

### 3.6 Cas d'usage du Consumer Standalone

- **Traitement batch** - Un seul processus qui lit tout le topic
- **Export de donnÃ©es** - Dumper tout le topic vers un fichier
- **Monitoring** - Observer tous les messages sans les marquer comme consommÃ©s
- **DÃ©veloppement/Debug** - SimplicitÃ© de configuration

---

## ğŸš€ Partie 4 - Scalable Consumer (avec consumer group)

### 4.1 Structure du Scalable Consumer

Le module `scalable-consumer` contient:
- **ScalableConsumerApplication.java** - Point d'entrÃ©e Spring Boot
- **KafkaConsumerConfig.java** - Configuration avec ConsumerFactory et consumer group
- **MessageConsumerService.java** - Consommation via @KafkaListener
- **Message.java** - ModÃ¨le de donnÃ©es
- **application.yml** - Configuration par dÃ©faut (instance 1)
- **application-instance2.yml** - Configuration pour instance 2

### 4.2 CaractÃ©ristiques du Scalable Consumer

- âœ… Utilise `@KafkaListener` avec un `groupId`
- âœ… **Consumer group** activÃ©
- âœ… **Rebalancing automatique** des partitions
- âœ… Chaque message consommÃ© par **une seule instance** du groupe
- âœ… **ScalabilitÃ© horizontale** - ajoutez plus d'instances pour augmenter le dÃ©bit
- âœ… **TolÃ©rance aux pannes** - si une instance tombe, les autres rÃ©cupÃ¨rent ses partitions

### 4.3 Lancer la premiÃ¨re instance

**Terminal 1:**

```bash
cd scalable-consumer
mvn spring-boot:run
```

**Via IntelliJ:**
1. Ouvrez `scalable-consumer/src/main/java/com/kafka/training/scalableconsumer/ScalableConsumerApplication.java`
2. Clic droit â†’ Run 'ScalableConsumerApplication'

**Observer les logs:**

```
Consumer group: message-consumer-group
Assigned partitions: [messages-0, messages-1, messages-2, messages-3]
```

L'instance 1 consomme **les 4 partitions**.

### 4.4 Lancer la deuxiÃ¨me instance

**Terminal 2:**

```bash
cd scalable-consumer
mvn spring-boot:run -Dspring-boot.run.profiles=instance2
```

**Via IntelliJ:**
1. Clic droit sur `ScalableConsumerApplication`
2. Modify Run Configuration â†’ Duplicate
3. Dans "Program arguments", ajoutez: `--spring.profiles.active=instance2`
4. Cochez "Allow multiple instances"
5. Run

**Observer les logs:**

**Instance 1:**
```
Consumer rebalancing...
New assigned partitions: [messages-0, messages-1]
```

**Instance 2:**
```
Consumer group: message-consumer-group
Assigned partitions: [messages-2, messages-3]
```

Les 4 partitions sont maintenant **rÃ©parties entre les 2 instances**!

### 4.5 Tester la consommation parallÃ¨le

**Envoyez un batch de 100 messages:**

```bash
curl -X POST http://localhost:8081/api/messages/send-batch \
  -H "Content-Type: application/json" \
  -d '{
    "topic": "messages",
    "count": 100,
    "sender": "ParallelTest"
  }'
```

**Observer:**
- Instance 1 consomme les messages des partitions 0 et 1
- Instance 2 consomme les messages des partitions 2 et 3
- Les deux instances travaillent **en parallÃ¨le**
- Chaque message est consommÃ© par **une seule instance**

### 4.6 Tester la rÃ©silience

**ArrÃªtez l'instance 2** (Ctrl+C dans le terminal 2).

**Observer dans les logs de l'instance 1:**

```
Consumer rebalancing...
New assigned partitions: [messages-0, messages-1, messages-2, messages-3]
```

L'instance 1 a **automatiquement rÃ©cupÃ©rÃ©** les partitions 2 et 3!

**Envoyez de nouveaux messages:**

```bash
curl -X POST http://localhost:8081/api/messages/send-batch \
  -H "Content-Type: application/json" \
  -d '{
    "topic": "messages",
    "count": 50,
    "sender": "ResilienceTest"
  }'
```

Tous les messages sont maintenant traitÃ©s par l'instance 1.

### 4.7 Relancer l'instance 2

**RedÃ©marrez l'instance 2:**

```bash
cd scalable-consumer
mvn spring-boot:run -Dspring-boot.run.profiles=instance2
```

**Observer:** Un nouveau rebalancing se produit, les partitions sont Ã  nouveau rÃ©parties 2-2.

---

## ğŸ“Š Partie 5 - Analyse et Comparaison

### 5.1 Comparaison Consumer Standalone vs Scalable

| Aspect | Consumer Standalone | Scalable Consumer |
|--------|---------------------|-------------------|
| **API Kafka** | `consumer.assign()` | `consumer.subscribe()` |
| **Spring** | KafkaConsumer bean + Thread | @KafkaListener |
| **Consumer Group** | âŒ Pas de group.id | âœ… group.id requis |
| **Partitions** | Toutes assignÃ©es manuellement | Distribution automatique |
| **Rebalancing** | âŒ Aucun | âœ… Automatique |
| **ScalabilitÃ©** | âŒ Une seule instance | âœ… Multiples instances |
| **TolÃ©rance pannes** | âŒ Aucune | âœ… Rebalancing automatique |
| **Cas d'usage** | Batch, export, monitoring | Production, haute disponibilitÃ© |

### 5.2 VÃ©rifier le consumer group

```bash
docker exec kafka kafka-consumer-groups \
  --bootstrap-server localhost:9092 \
  --describe \
  --group message-consumer-group
```

**Sortie attendue (2 instances actives):**

```
GROUP                   TOPIC      PARTITION  CURRENT-OFFSET  LOG-END-OFFSET  LAG  CONSUMER-ID                                     HOST
message-consumer-group  messages   0          50              50              0    consumer-1-uuid                                  /172.18.0.1
message-consumer-group  messages   1          48              48              0    consumer-1-uuid                                  /172.18.0.1
message-consumer-group  messages   2          52              52              0    consumer-2-uuid                                  /172.18.0.1
message-consumer-group  messages   3          50              50              0    consumer-2-uuid                                  /172.18.0.1
```

**Observation:**
- LAG = 0 â†’ tous les messages ont Ã©tÃ© consommÃ©s
- Chaque consumer-id est responsable de 2 partitions
- HOST montre l'adresse IP du consumer

### 5.3 Observer dans Kafka UI

Ouvrez http://localhost:8080:

1. **Topics** â†’ `messages`:
   - Voir les messages produits
   - Observer la distribution par partition

2. **Consumer Groups** â†’ `message-consumer-group`:
   - Voir les members du groupe
   - Voir les partitions assignÃ©es Ã  chaque member
   - Observer les offsets et le lag

---

## ğŸ¯ Livrables

Ã€ la fin de cet exercice, vous devez Ãªtre capable de:

### Producer
- [ ] CrÃ©er un Producer Spring Boot avec KafkaTemplate
- [ ] Configurer la sÃ©rialisation JSON
- [ ] Produire des messages via une API REST
- [ ] Comprendre le rÃ´le de la clÃ© dans le partitionnement
- [ ] Envoyer des messages avec et sans clÃ©

### Consumer Standalone
- [ ] CrÃ©er un consumer sans consumer group
- [ ] Utiliser `consumer.assign()` pour assigner manuellement les partitions
- [ ] Configurer la dÃ©sÃ©rialisation JSON avec trusted packages
- [ ] Construire dynamiquement la liste des partitions
- [ ] Comprendre les cas d'usage du mode standalone

### Scalable Consumer
- [ ] CrÃ©er un consumer avec consumer group
- [ ] Utiliser @KafkaListener avec groupId
- [ ] Lancer plusieurs instances en parallÃ¨le
- [ ] Observer le rebalancing automatique des partitions
- [ ] Tester la tolÃ©rance aux pannes
- [ ] Analyser les consumer groups et les offsets

---

## ğŸ§¹ Nettoyage

### ArrÃªter les applications

1. ArrÃªtez le producer (Ctrl+C)
2. ArrÃªtez le consumer standalone (Ctrl+C)
3. ArrÃªtez les scalable consumers (Ctrl+C dans chaque terminal)

### ArrÃªter Kafka

```bash
docker-compose down
```

### Nettoyage complet (avec suppression des volumes)

```bash
docker-compose down -v
```

---

## ğŸ“š Concepts ClÃ©s

### Producer

- **KafkaTemplate**: Abstraction Spring pour envoyer des messages
- **JsonSerializer**: Convertit les objets Java en JSON
- **ClÃ© de partitionnement**: Hash(clÃ©) % nombre_partitions
- **MAX_BLOCK_MS_CONFIG**: Timeout pour attendre les mÃ©tadonnÃ©es (Ã©vite les boucles infinies)
- **Callback**: DÃ©tecte les succÃ¨s/Ã©checs d'envoi

### Consumer Standalone

- **KafkaConsumer**: API Kafka native
- **assign()**: Assignation manuelle des partitions (pas de consumer group)
- **poll()**: RÃ©cupÃ¨re les messages par batch
- **seekToBeginning()**: Lit depuis le dÃ©but du topic
- **Pas de rebalancing**: Toutes les partitions assignÃ©es Ã  l'instance unique

### Scalable Consumer

- **@KafkaListener**: Annotation Spring pour Ã©couter un topic
- **groupId**: Identifiant du consumer group
- **ConsumerFactory**: Factory Spring pour crÃ©er des consumers
- **Rebalancing**: Redistribution automatique des partitions entre les membres du groupe
- **ISR (In-Sync Replicas)**: Garantit qu'aucun message n'est perdu

### Configuration Commune

- **bootstrap-servers**: Adresse du cluster Kafka
- **JsonDeserializer.TRUSTED_PACKAGES**: SÃ©curitÃ© pour la dÃ©sÃ©rialisation
- **JsonDeserializer.USE_TYPE_INFO_HEADERS**: Ignore les headers de type du producer
- **auto-offset-reset**: earliest (depuis le dÃ©but) ou latest (nouveaux messages)
- **enable-auto-commit**: Commit automatique des offsets (true par dÃ©faut)

---

## ğŸ” Pour Aller Plus Loin

### 1. Manual Offset Management

DÃ©sactivez `enable-auto-commit` et gÃ©rez manuellement les offsets:

```java
@KafkaListener(...)
public void consume(ConsumerRecord<String, Message> record, Acknowledgment ack) {
    try {
        processMessage(record.value());
        ack.acknowledge(); // Commit manuel
    } catch (Exception e) {
        // Gestion d'erreur - ne pas commit
    }
}
```

### 2. Error Handling

Ajoutez un error handler pour gÃ©rer les erreurs de dÃ©sÃ©rialisation:

```java
@Bean
public DefaultErrorHandler errorHandler() {
    return new DefaultErrorHandler(new FixedBackOff(1000L, 3));
}
```

### 3. Concurrency

Augmentez le nombre de threads par consumer:

```java
factory.setConcurrency(3); // 3 threads par instance
```

Chaque thread peut consommer une partition en parallÃ¨le.

### 4. Custom Partitioner

CrÃ©ez votre propre stratÃ©gie de partitionnement:

```java
public class CustomPartitioner implements Partitioner {
    @Override
    public int partition(String topic, Object key, byte[] keyBytes,
                        Object value, byte[] valueBytes, Cluster cluster) {
        // Logique personnalisÃ©e
        return Math.abs(key.hashCode()) % numPartitions;
    }
}
```

### 5. Consumer avec seek()

Lire depuis un offset spÃ©cifique:

```java
consumer.seek(new TopicPartition("messages", 0), 100);
```

---

## ğŸ› Troubleshooting

### Erreur: "The class 'X' is not in the trusted packages"

**Solution:**
```java
deserializer.addTrustedPackages("*");
deserializer.setUseTypeHeaders(false);
```

### Erreur: "No group.id found in consumer config"

**Solution:** Ajoutez `groupId` dans @KafkaListener ou utilisez `assign()` au lieu de `subscribe()`.

### Les messages ne sont pas consommÃ©s

1. VÃ©rifiez que le topic existe
2. VÃ©rifiez que le producer a bien envoyÃ© les messages
3. VÃ©rifiez les logs du consumer pour les erreurs
4. VÃ©rifiez le lag du consumer group

### Rebalancing infini

**Cause:** Le traitement des messages prend trop de temps.

**Solution:** Augmentez `max.poll.interval.ms`:

```yaml
spring:
  kafka:
    consumer:
      properties:
        max.poll.interval.ms: 600000  # 10 minutes
```

---

**Bravo! Vous maÃ®trisez maintenant les bases du Producer et Consumer Spring Boot avec Kafka! ğŸš€**
