# Exercice 3 - Kafka Streams avec Spring Boot

## ğŸ¯ Objectifs

- Comprendre les concepts de Kafka Streams
- CrÃ©er une pipeline de traitement de flux
- Explorer l'API Admin de Kafka
- Manipuler KStream et KTable
- Faire des jointures entre streams et tables
- Utiliser des topics compactÃ©s pour les donnÃ©es de rÃ©fÃ©rence
- Visualiser la topologie Kafka Streams
- Comprendre les transformations et agrÃ©gations

## ğŸ“‹ PrÃ©requis

- Docker et Docker Compose
- Java 17+
- Maven 3.8+
- Ports disponibles: 8080 (Kafka UI), 8081 (Producer), 8082 (Streams), 9092 (Kafka)

## ğŸ—ï¸ Architecture

```
Producer (Spring Boot)
    â†“
    â”œâ”€> user-events (topic normal)
    â””â”€> user-profiles (topic compactÃ©)

Kafka Streams (Spring Boot)
    â†“
    Lit user-events
    â†“
    Filtre PURCHASE
    â†“
    Ã‰crit dans filtered-events
```

## ğŸ“¦ Structure du Projet

```
exercice3-kafka-streams/
â”œâ”€â”€ pom.xml                 # Maven parent
â”œâ”€â”€ docker-compose.yml      # Infrastructure Kafka
â”œâ”€â”€ Makefile               # Commandes utiles
â”‚
â”œâ”€â”€ common/                # Module partagÃ©
â”‚   â”œâ”€â”€ pom.xml
â”‚   â””â”€â”€ src/main/java/com/kafka/training/common/
â”‚       â”œâ”€â”€ model/
â”‚       â”‚   â”œâ”€â”€ Event.java           # ModÃ¨le partagÃ©
â”‚       â”‚   â”œâ”€â”€ UserProfile.java     # ModÃ¨le partagÃ©
â”‚       â”‚   â””â”€â”€ EnrichedEvent.java   # ModÃ¨le partagÃ©
â”‚       â””â”€â”€ serde/
â”‚           â””â”€â”€ JsonSerde.java       # Serde JSON personnalisÃ©
â”‚
â”œâ”€â”€ producer/              # Module Producer
â”‚   â”œâ”€â”€ pom.xml
â”‚   â””â”€â”€ src/main/java/com/kafka/training/producer/
â”‚       â”œâ”€â”€ ProducerApplication.java
â”‚       â”œâ”€â”€ config/
â”‚       â”‚   â””â”€â”€ KafkaConfig.java        # API Admin + Producer
â”‚       â”œâ”€â”€ service/
â”‚       â”‚   â””â”€â”€ EventProducerService.java
â”‚       â””â”€â”€ controller/
â”‚           â””â”€â”€ ProducerController.java  # REST API
â”‚
â””â”€â”€ streams/               # Module Kafka Streams
    â”œâ”€â”€ pom.xml
    â””â”€â”€ src/main/java/com/kafka/training/streams/
        â”œâ”€â”€ StreamsApplication.java
        â”œâ”€â”€ config/
        â”‚   â””â”€â”€ KafkaStreamsConfig.java
        â””â”€â”€ topology/
            â””â”€â”€ EventStreamTopology.java  # Pipeline Ã  faire Ã©voluer
```

**Note importante :** Le module `common` centralise les modÃ¨les de donnÃ©es et le JsonSerde, Ã©vitant ainsi les problÃ¨mes de dÃ©sÃ©rialisation entre le producer et le streams.

---

## ğŸš€ Partie 1 - DÃ©marrage

### 1.1 Lancer l'infrastructure

```bash
cd jour2/exercice3-kafka-streams
make start
```

Cela dÃ©marre :
- **Kafka** (port 9092)
- **Kafka UI** (port 8080)

â³ **Attendre 30 secondes** pour le dÃ©marrage complet.

### 1.2 Compiler les projets

```bash
make build
```

---

## ğŸ”§ Partie 2 - API Admin Kafka

### 2.1 Comment sont crÃ©Ã©s les topics ?

Les topics sont crÃ©Ã©s **de maniÃ¨re programmatique** via l'**API Kafka Admin** au dÃ©marrage du producer.

Ouvrez `producer/src/main/java/com/kafka/training/producer/config/KafkaConfig.java`

#### Configuration de l'Admin Client

```java
@Bean
public KafkaAdmin kafkaAdmin() {
    Map<String, Object> configs = new HashMap<>();
    configs.put(AdminClientConfig.BOOTSTRAP_SERVERS_CONFIG, bootstrapServers);
    return new KafkaAdmin(configs);
}
```

Spring dÃ©tecte automatiquement tous les beans `NewTopic` et les crÃ©e via le `KafkaAdmin` au dÃ©marrage.

#### Topic `user-events` (normal)

```java
@Bean
public NewTopic userEventsTopic() {
    return TopicBuilder.name("user-events")
            .partitions(3)          // 3 partitions pour parallÃ©lisme
            .replicas(1)            // 1 rÃ©plica (cluster Ã  1 broker)
            .build();
}
```

#### Topic `user-profiles` (compactÃ©)

```java
@Bean
public NewTopic userProfilesTopic() {
    return TopicBuilder.name("user-profiles")
            .partitions(3)
            .replicas(1)
            .compact()              // cleanup.policy=compact
            .build();
}
```

â˜ï¸ **Important :** Le `.compact()` configure `cleanup.policy=compact`, ce qui signifie que Kafka ne conserve que **la derniÃ¨re valeur par clÃ©**. C'est essentiel pour les **KTable** car elles reprÃ©sentent un Ã©tat actuel (et non un historique).

#### Topic `filtered-events` (sortie)

```java
@Bean
public NewTopic filteredEventsTopic() {
    return TopicBuilder.name("filtered-events")
            .partitions(3)
            .replicas(1)
            .build();
}
```

### 2.2 Pourquoi utiliser l'API Admin ?

| Avantage | Description |
|----------|-------------|
| **ContrÃ´le total** | Nombre de partitions, replicas, compaction, rÃ©tention, etc. |
| **Reproductible** | Configuration dans le code, versionnÃ©e avec Git |
| **PÃ©dagogique** | Les Ã©lÃ¨ves voient explicitement la configuration des topics |
| **Production-ready** | Bonne pratique pour les environnements rÃ©els |

âš ï¸ **Alternative :** Kafka peut crÃ©er automatiquement les topics (`auto.create.topics.enable=true`), mais **sans contrÃ´le** sur les paramÃ¨tres (partitions par dÃ©faut, pas de compaction, etc.).

### 2.3 Lancer le Producer

Dans un terminal :

```bash
make run-producer
```

Le producer dÃ©marre sur **http://localhost:8081** et crÃ©e automatiquement les topics.

### 2.4 VÃ©rifier les topics crÃ©Ã©s

Dans un autre terminal :

```bash
make topics
```

**RÃ©sultat attendu :**
```
user-events
user-profiles
```

### 2.5 DÃ©tails des topics

```bash
make describe-topics
```

Observez la diffÃ©rence entre :
- `user-events` : topic normal avec `cleanup.policy=delete`
- `user-profiles` : topic compactÃ© avec `cleanup.policy=compact`

---

## ğŸ“Š Partie 3 - GÃ©nÃ©rer des DonnÃ©es

### 3.1 Initialiser les profils utilisateurs

```bash
make init-data
```

Cela crÃ©e 5 profils dans le topic `user-profiles` (compactÃ©) :
- user1: Alice (France, GOLD)
- user2: Bob (USA, SILVER)
- user3: Charlie (Germany, BRONZE)
- user4: Diana (UK, GOLD)
- user5: Eve (Spain, SILVER)

### 3.2 GÃ©nÃ©rer des Ã©vÃ©nements

```bash
make generate
```

GÃ©nÃ¨re 20 Ã©vÃ©nements alÃ©atoires (PURCHASE, LOGIN, LOGOUT, VIEW, ADD_TO_CART).

### 3.3 Consommer les topics

**Ã‰vÃ©nements :**
```bash
make consume-events
```

**Profils (avec clÃ©s) :**
```bash
make consume-profiles
```

Observez que les profils affichent `userId:{"userId":"user1",...}` car le topic est compactÃ© avec userId comme clÃ©.

---

## ğŸŒŠ Partie 4 - Pipeline Kafka Streams Simple

### 4.1 Comprendre la topologie initiale

Ouvrez `streams/src/main/java/com/kafka/training/streams/topology/EventStreamTopology.java`

La pipeline actuelle :
1. Lit `user-events`
2. Filtre uniquement les `PURCHASE`
3. Ã‰crit dans `filtered-events`

```java
KStream<String, Event> eventsStream = streamsBuilder
    .stream("user-events", Consumed.with(Serdes.String(), eventSerde));

KStream<String, Event> purchaseStream = eventsStream
    .filter((key, event) -> "PURCHASE".equals(event.getEventType()));

purchaseStream.to("filtered-events", Produced.with(Serdes.String(), eventSerde));
```

### 4.2 Lancer Kafka Streams

Dans un nouveau terminal :

```bash
make run-streams
```

L'application dÃ©marre sur **port 8082**.

**Observez les logs :**
- La topologie s'affiche au dÃ©marrage
- Les Ã©vÃ©nements sont traitÃ©s en temps rÃ©el

### 4.3 VÃ©rifier le rÃ©sultat

```bash
make consume-filtered
```

Vous ne verrez que les Ã©vÃ©nements `PURCHASE` !

### 4.4 Visualiser dans Kafka UI

Allez sur http://localhost:8080

1. Cliquez sur **Topics**
2. Observez les topics crÃ©Ã©s :
   - `user-events`
   - `user-profiles` (icÃ´ne de compactage)
   - `filtered-events`
3. Consultez les messages dans chaque topic

### 4.5 Visualiser la topologie

La topologie Kafka Streams est exposÃ©e via une API REST sur le module streams.

**Option 1 : API JSON**
```bash
make show-topology
```

**Option 2 : Description texte**
```bash
curl http://localhost:8082/api/topology/describe
```

**Option 3 : Visualisation graphique**

1. Allez sur https://zz85.github.io/kafka-streams-viz/
2. RÃ©cupÃ©rez la topologie :
   ```bash
   curl http://localhost:8082/api/topology/describe
   ```
3. Collez le rÃ©sultat dans le visualiseur
4. Admirez votre pipeline en graphe ! ğŸ¨

---

## ğŸ“ Partie 5 - Exercices Kafka Streams

### Exercice 1 : CrÃ©er un KTable depuis user-profiles

**Objectif :** Charger les profils utilisateurs dans un KTable.

<details>
<summary>Indice</summary>

Un KTable est une table mise Ã  jour en continu depuis un topic compactÃ©.

```java
KTable<String, UserProfile> userProfileTable = streamsBuilder
    .table("user-profiles",
           Consumed.with(Serdes.String(), userProfileSerde));
```
</details>

<details>
<summary>Solution</summary>

Dans `EventStreamTopology.java`, ajoutez aprÃ¨s la dÃ©finition de `purchaseStream` :

```java
// KTable depuis le topic compactÃ©
KTable<String, UserProfile> userProfileTable = streamsBuilder
    .table("user-profiles",
           Consumed.with(Serdes.String(), userProfileSerde),
           Materialized.as("user-profiles-store"));
```

Relancez Kafka Streams et observez les logs.
</details>

---

### Exercice 2 : Jointure Stream-Table

**Objectif :** Enrichir les achats avec les informations utilisateur (nom, tier).

<details>
<summary>Indice</summary>

Utilisez `join()` entre le KStream et le KTable :

```java
KStream<String, EnrichedEvent> enrichedStream = purchaseStream.join(
    userProfileTable,
    (event, profile) -> { /* crÃ©er EnrichedEvent */ }
);
```
</details>

<details>
<summary>Solution</summary>

```java
// Jointure : enrichir les achats avec les profils
KStream<String, EnrichedEvent> enrichedStream = purchaseStream.join(
    userProfileTable,
    (event, profile) -> {
        EnrichedEvent enriched = new EnrichedEvent();
        enriched.setUserId(event.getUserId());
        enriched.setEventType(event.getEventType());
        enriched.setAmount(event.getAmount());
        enriched.setCountry(event.getCountry());
        enriched.setTimestamp(event.getTimestamp());
        enriched.setUserName(profile.getName());
        enriched.setUserTier(profile.getTier());
        return enriched;
    }
);

// Ã‰crire dans un nouveau topic
enrichedStream.to("enriched-events",
                  Produced.with(Serdes.String(), enrichedEventSerde));
```

Ajoutez dans `KafkaConfig.java` le topic de sortie :

```java
@Bean
public NewTopic enrichedEventsTopic() {
    return TopicBuilder.name("enriched-events")
            .partitions(3)
            .replicas(1)
            .build();
}
```
</details>

---

### Exercice 3 : Filtrer les achats GOLD

**Objectif :** Ne garder que les achats des utilisateurs GOLD.

<details>
<summary>Solution</summary>

```java
KStream<String, EnrichedEvent> goldPurchases = enrichedStream
    .filter((key, event) -> "GOLD".equals(event.getUserTier()))
    .peek((key, event) -> log.info("GOLD purchase: user={}, amount={}",
                                    event.getUserName(), event.getAmount()));

goldPurchases.to("gold-purchases",
                 Produced.with(Serdes.String(), enrichedEventSerde));
```
</details>

---

### Exercice 4 : Compter les achats par utilisateur

**Objectif :** CrÃ©er une table d'agrÃ©gation avec le nombre d'achats par user.

<details>
<summary>Indice</summary>

Utilisez `groupByKey()` puis `count()` :

```java
KTable<String, Long> purchaseCount = purchaseStream
    .groupByKey()
    .count();
```
</details>

<details>
<summary>Solution</summary>

```java
// Compter les achats par utilisateur
KTable<String, Long> purchaseCountTable = purchaseStream
    .groupByKey(Grouped.with(Serdes.String(), eventSerde))
    .count(Materialized.as("purchase-count-store"));

// Convertir en stream pour logger
purchaseCountTable.toStream()
    .peek((userId, count) -> log.info("User {} has {} purchases", userId, count));
```

Le state store `purchase-count-store` est crÃ©Ã© automatiquement.
</details>

---

### Exercice 5 : Somme des montants par pays

**Objectif :** Calculer le total dÃ©pensÃ© par pays.

<details>
<summary>Solution</summary>

```java
// Grouper par pays et sommer les montants
KTable<String, Double> totalByCountry = purchaseStream
    .groupBy(
        (key, event) -> event.getCountry(),
        Grouped.with(Serdes.String(), eventSerde)
    )
    .aggregate(
        () -> 0.0,  // Valeur initiale
        (country, event, total) -> total + event.getAmount(),
        Materialized.with(Serdes.String(), Serdes.Double())
    );

totalByCountry.toStream()
    .peek((country, total) -> log.info("Country {} total: {}", country, total));
```
</details>

---

### Exercice 6 : FenÃªtres temporelles (AVANCÃ‰)

**Objectif :** Compter les achats par fenÃªtre de 1 minute.

<details>
<summary>Solution</summary>

```java
// FenÃªtre tumbling de 1 minute
KTable<Windowed<String>, Long> windowedCount = purchaseStream
    .groupByKey(Grouped.with(Serdes.String(), eventSerde))
    .windowedBy(TimeWindows.ofSizeWithNoGrace(Duration.ofMinutes(1)))
    .count();

windowedCount.toStream()
    .peek((windowed, count) ->
        log.info("Window [{} - {}]: user={}, count={}",
                 windowed.window().startTime(),
                 windowed.window().endTime(),
                 windowed.key(),
                 count));
```
</details>

---

## ğŸ“Š Partie 6 - Visualisation Kafka UI

### 6.1 Explorer les topics

Sur http://localhost:8080 :

1. **Topics** â†’ `user-profiles`
   - Observez `cleanup.policy=compact`
   - Les clÃ©s sont visibles (userId)

2. **Topics** â†’ `filtered-events`
   - Uniquement des PURCHASE

3. **Topics** â†’ `enriched-events` (si crÃ©Ã©)
   - Ã‰vÃ©nements avec nom et tier

### 6.2 Consumer Groups

1. **Consumers** â†’ `event-processor`
   - C'est l'application Kafka Streams
   - Observez les partitions assignÃ©es
   - Lag = 0 si tout est traitÃ©

---

## ğŸ¯ Partie 7 - Concepts ClÃ©s

### KStream vs KTable

| Aspect | KStream | KTable |
|--------|---------|--------|
| Nature | Flux d'Ã©vÃ©nements | Ã‰tat actuel |
| DonnÃ©es | Tous les Ã©vÃ©nements | DerniÃ¨re valeur par clÃ© |
| Topic | Normal (delete) | CompactÃ© (compact) |
| Utilisation | Transformations, filtres | Jointures, lookups |

### GlobalKTable vs KTable

| KTable | GlobalKTable |
|--------|--------------|
| PartitionnÃ© | RÃ©pliquÃ© entiÃ¨rement |
| Rejoint sur la clÃ© | Rejoint sur n'importe quoi |
| Moins de mÃ©moire | Plus de mÃ©moire |
| Plus rapide | Lookup flexible |

**Dans cet exercice, on utilise KTable sans RocksDB car les donnÃ©es sont petites.**

### Topic CompactÃ©

- Conserve uniquement la **derniÃ¨re valeur par clÃ©**
- UtilisÃ© pour les donnÃ©es de rÃ©fÃ©rence (users, config, etc.)
- IdÃ©al pour les KTable

---

## ğŸ§ª Partie 8 - Tests et DÃ©bug

### 8.1 GÃ©nÃ©rer beaucoup d'Ã©vÃ©nements

```bash
make generate-100
```

Observez dans Kafka Streams :
- Le traitement en temps rÃ©el
- Les agrÃ©gations qui se mettent Ã  jour

### 8.2 Modifier un profil utilisateur

```bash
curl -X POST http://localhost:8081/api/profiles \
  -H "Content-Type: application/json" \
  -d '{
    "userId": "user1",
    "name": "Alice Updated",
    "country": "France",
    "tier": "PLATINUM"
  }'
```

Le topic compactÃ© ne gardera que la derniÃ¨re version !

### 8.3 Voir la topologie

Dans les logs de Kafka Streams au dÃ©marrage, vous verrez :

```
Topologies:
   Sub-topology: 0
    Source: KSTREAM-SOURCE-0000000000 (topics: [user-events])
      --> KSTREAM-FILTER-0000000001
    Processor: KSTREAM-FILTER-0000000001 (stores: [])
      --> KSTREAM-SINK-0000000002
    Sink: KSTREAM-SINK-0000000002 (topic: filtered-events)
```

---

## ğŸ§¹ Nettoyage

```bash
# ArrÃªter les services
make stop

# Nettoyage complet (supprime aussi les volumes)
make clean
```

---

## ğŸ“š Ressources

- [Kafka Streams Documentation](https://kafka.apache.org/documentation/streams/)
- [Spring Kafka Streams](https://docs.spring.io/spring-kafka/reference/html/#kafka-streams)
- [Kafka Admin API](https://kafka.apache.org/documentation/#adminapi)

---

**Bravo ! Vous maÃ®trisez maintenant Kafka Streams ! ğŸŒŠ**
