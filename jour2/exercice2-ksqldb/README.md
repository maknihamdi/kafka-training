# Exercice 2 - ksqlDB : Stream Processing SQL

## üéØ Objectifs

- Comprendre la diff√©rence entre STREAMS et TABLES
- Filtrer et transformer des flux de donn√©es avec SQL
- Cr√©er des agr√©gations en temps r√©el
- Utiliser les fen√™tres temporelles (windowing)
- Joindre des streams et des tables
- Comprendre les topics compact√©s

## üìã Pr√©requis

- Docker et Docker Compose
- Bash (shell Unix/Linux standard)
- Ports disponibles: 8080, 8088, 9092

## üèóÔ∏è Architecture Simplifi√©e

```
Script Shell (generate_events.sh)
    ‚Üì
Topic Kafka: user_events
    ‚Üì
ksqlDB Server (traitement SQL)
    ‚Üì
Streams & Tables d√©riv√©s
```

---

## üöÄ Partie 1 - D√©marrage

### 1.1 Lancer l'infrastructure

```bash
cd jour2/exercice2-ksqldb
make start
```

Cela d√©marre:
- **Kafka** (port 9092)
- **ksqlDB Server** (port 8088)
- **Kafka UI** (port 8080)

‚è≥ **Attendre 60 secondes** pour le d√©marrage complet.

### 1.2 V√©rifier le statut

```bash
make status
```

Tous les services doivent √™tre d√©marr√©s et pr√™ts.

---

## üìä Partie 2 - G√©n√©rer des Donn√©es

### 2.1 G√©n√©rer les √©v√©nements de test

Le script `generate_events.sh` lit les donn√©es depuis `scripts/events_data.txt` et les envoie vers Kafka.

```bash
make generate
```

**R√©sultat attendu:**
```
üìä Envoi de 50 √©v√©nements...

[  1/ 50] PURCHASE         | User 101 |      50.00 | France
[  2/ 50] LOGIN            | User 102 |        N/A | USA
[  3/ 50] PURCHASE         | User 103 |     120.50 | France
...
‚úÖ 50 √©v√©nements envoy√©s avec succ√®s!
```

### 2.2 V√©rifier les donn√©es dans Kafka

```bash
make consume
```

Vous devriez voir les √©v√©nements JSON:
```json
{"user_id": 105, "event_type": "PURCHASE", "amount": 234.5, "country": "France", "event_time": 1733...}
```

### 2.3 Mode continu (optionnel)

Pour g√©n√©rer des √©v√©nements en continu (1 √©v√©nement toutes les 2 secondes):
```bash
make generate-continuous
```

Le script s√©lectionne al√©atoirement des √©v√©nements depuis `events_data.txt` et les envoie en boucle. Appuyez sur `Ctrl+C` pour arr√™ter.

---

## üîß Partie 3 - Charger le Setup ksqlDB

Maintenant que les donn√©es sont dans Kafka, chargez les streams de base :

```bash
make ksql-setup
```

Cela cr√©e :
- `user_events_stream` - Tous les √©v√©nements utilisateurs
- `purchases_stream` - Uniquement les achats (filtre PURCHASE)

**V√©rifier :**
```bash
make ksql-streams
```

**R√©sultat attendu :**
```
 Stream Name         | Kafka Topic      | Key Format | Value Format
---------------------------------------------------------------------
 PURCHASES_STREAM    | PURCHASES_STREAM | KAFKA      | JSON
 USER_EVENTS_STREAM  | user_events      | KAFKA      | JSON
```

---

## üî∑ Partie 4 - Explorer avec ksqlDB CLI

### 4.1 Se connecter au CLI ksqlDB

```bash
make ksql
```

Vous √™tes maintenant dans l'interface interactive ksqlDB!

### 4.2 Voir les streams existants

```sql
SHOW STREAMS;
```

### 4.3 Consulter les donn√©es en temps r√©el

```sql
-- Voir tous les √©v√©nements
SELECT * FROM user_events_stream EMIT CHANGES LIMIT 10;
```

**R√©sultat attendu:**
```
+----------+------------+--------+---------+---------------+
| USER_ID  | EVENT_TYPE | AMOUNT | COUNTRY | EVENT_TIME    |
+----------+------------+--------+---------+---------------+
| 105      | PURCHASE   | 234.5  | France  | 1733071234567 |
| 112      | LOGIN      | null   | USA     | 1733071234568 |
...
```

**Note:** `EMIT CHANGES` signifie que la requ√™te reste ouverte et affiche les nouveaux √©v√©nements. Appuyez sur `Ctrl+C` pour arr√™ter.

```sql
-- Voir uniquement les achats
SELECT * FROM purchases_stream EMIT CHANGES LIMIT 5;
```

---

## üîß Partie 5 - Cr√©er Vos Propres Streams

### 5.1 Filtrer les achats en France

```sql
CREATE STREAM french_purchases AS
    SELECT *
    FROM purchases_stream
    WHERE country = 'France'
    EMIT CHANGES;
```

**V√©rifier:**
```sql
SELECT * FROM french_purchases EMIT CHANGES LIMIT 5;
```

### 5.2 D√©tecter les achats > 100‚Ç¨

```sql
CREATE STREAM high_value_purchases AS
    SELECT user_id, amount, country
    FROM purchases_stream
    WHERE amount > 100
    EMIT CHANGES;
```

### 5.3 Cat√©goriser les achats

```sql
CREATE STREAM categorized_purchases AS
    SELECT
        user_id,
        amount,
        country,
        CASE
            WHEN amount < 50 THEN 'SMALL'
            WHEN amount < 150 THEN 'MEDIUM'
            ELSE 'LARGE'
        END AS purchase_category,
        amount * 0.2 AS tax_amount
    FROM purchases_stream
    EMIT CHANGES;
```

**Tester:**
```sql
SELECT user_id, amount, purchase_category, tax_amount
FROM categorized_purchases
EMIT CHANGES
LIMIT 5;
```

---

## üìà Partie 6 - Cr√©er des Tables avec Agr√©gations

### 6.1 Total d√©pens√© par utilisateur

```sql
CREATE TABLE user_total_spent AS
    SELECT
        user_id,
        COUNT(*) AS purchase_count,
        SUM(amount) AS total_spent,
        AVG(amount) AS avg_spent
    FROM purchases_stream
    GROUP BY user_id
    EMIT CHANGES;
```

**Important:** Cette table utilise un **topic compact√©** automatiquement!

**Consulter la table (pull query):**
```sql
SELECT * FROM user_total_spent;
```

**R√©sultat attendu:**
```
+----------+----------------+-------------+-----------+
| USER_ID  | PURCHASE_COUNT | TOTAL_SPENT | AVG_SPENT |
+----------+----------------+-------------+-----------+
| 105      | 3              | 567.25      | 189.08    |
| 112      | 2              | 234.99      | 117.50    |
...
```

**V√©rifier le topic compact√©:**

Quittez ksqlDB (`exit`), puis:
```bash
docker exec kafka kafka-topics --bootstrap-server localhost:9092 \
  --describe --topic USER_TOTAL_SPENT
```

Vous devriez voir `cleanup.policy=compact` !

### 6.2 Statistiques par pays

```sql
CREATE TABLE purchases_by_country AS
    SELECT
        country,
        COUNT(*) AS purchase_count,
        SUM(amount) AS total_amount,
        AVG(amount) AS avg_amount
    FROM purchases_stream
    GROUP BY country
    EMIT CHANGES;
```

**Consulter:**
```sql
SELECT * FROM purchases_by_country;
```

---

## ‚è±Ô∏è Partie 7 - Fen√™tres Temporelles (Windowing)

### 7.1 Fen√™tre TUMBLING (30 secondes)

```sql
CREATE TABLE purchases_by_country_windowed AS
    SELECT
        country,
        COUNT(*) AS purchase_count,
        SUM(amount) AS total_amount,
        WINDOWSTART AS window_start,
        WINDOWEND AS window_end
    FROM purchases_stream
    WINDOW TUMBLING (SIZE 30 SECONDS)
    GROUP BY country
    EMIT CHANGES;
```

**Observer en temps r√©el:**
```sql
SELECT
    country,
    purchase_count,
    total_amount,
    TIMESTAMPTOSTRING(window_start, 'HH:mm:ss') AS window_start_time
FROM purchases_by_country_windowed
EMIT CHANGES;
```

### 7.2 Tester le windowing

Dans un autre terminal, lancez le g√©n√©rateur en continu:
```bash
make generate-continuous
```

Retournez dans ksqlDB et observez les fen√™tres se cr√©er toutes les 30 secondes!

---

## üîó Partie 8 - Joindre Streams et Tables

### 8.1 Enrichir les achats avec les stats utilisateur

```sql
CREATE STREAM purchases_with_stats AS
    SELECT
        p.user_id,
        p.amount,
        u.total_spent AS user_total_spent,
        u.avg_spent AS user_avg_spent
    FROM purchases_stream p
    LEFT JOIN user_total_spent u ON p.user_id = u.user_id
    EMIT CHANGES;
```

**Observer:**
```sql
SELECT * FROM purchases_with_stats EMIT CHANGES LIMIT 5;
```

Chaque achat est enrichi avec les statistiques globales de l'utilisateur!

### 8.2 D√©tecter les achats au-dessus de la moyenne

```sql
CREATE STREAM above_average_purchases AS
    SELECT
        p.user_id,
        p.amount,
        u.avg_spent AS user_avg,
        p.amount - u.avg_spent AS amount_above_avg
    FROM purchases_stream p
    LEFT JOIN user_total_spent u ON p.user_id = u.user_id
    WHERE p.amount > u.avg_spent
    EMIT CHANGES;
```

---

## üìä Partie 9 - Explorer avec Kafka UI

### 9.1 Ouvrir Kafka UI

Allez sur http://localhost:8080

### 9.2 Explorer les streams et tables

1. Menu **"ksqlDB"** (√† gauche)
2. Voir la liste des streams et tables
3. Cliquer sur un stream pour voir les d√©tails
4. Ex√©cuter des requ√™tes directement dans l'interface

### 9.3 Voir les topics cr√©√©s

1. Menu **"Topics"**
2. Observer les topics cr√©√©s par ksqlDB:
   - `user_events` (source)
   - `PURCHASES_STREAM`
   - `FRENCH_PURCHASES`
   - `USER_TOTAL_SPENT` (compact√©!)

---

## üéì Exercices Pratiques

### Exercice 1 : √âv√©nements LOGIN par pays
Cr√©ez une table qui compte les √©v√©nements LOGIN par pays.

<details>
<summary>Solution</summary>

```sql
CREATE TABLE login_by_country AS
    SELECT
        country,
        COUNT(*) AS login_count
    FROM user_events_stream
    WHERE event_type = 'LOGIN'
    GROUP BY country
    EMIT CHANGES;
```
</details>

### Exercice 2 : Top utilisateurs d√©pensiers
Cr√©ez une requ√™te pour voir les 5 utilisateurs qui ont le plus d√©pens√©.

<details>
<summary>Solution</summary>

```sql
SELECT user_id, total_spent
FROM user_total_spent
ORDER BY total_spent DESC
LIMIT 5;
```
</details>

### Exercice 3 : Achats par fen√™tre de 1 minute
Cr√©ez une table avec fen√™tre HOPPING de 1 minute, avan√ßant toutes les 30 secondes.

<details>
<summary>Solution</summary>

```sql
CREATE TABLE purchases_hopping AS
    SELECT
        country,
        COUNT(*) AS purchase_count,
        SUM(amount) AS total_amount
    FROM purchases_stream
    WINDOW HOPPING (SIZE 1 MINUTE, ADVANCE BY 30 SECONDS)
    GROUP BY country
    EMIT CHANGES;
```
</details>

---

## üìù R√©sum√© des Concepts

### STREAM vs TABLE

| Aspect | STREAM | TABLE |
|--------|--------|-------|
| Nature | Flux d'√©v√©nements | √âtat actuel |
| Donn√©es | Append-only | Mise √† jour par cl√© |
| Topic | Retention normale | **Compact√©** |
| Utilisation | Filtres, transformations | Agr√©gations |

### Types de Fen√™tres

**TUMBLING (fixes):**
```
[0-30s] [30-60s] [60-90s]
```

**HOPPING (chevauchantes):**
```
[0-60s]
    [30-90s]
        [60-120s]
```

### Commandes Utiles

```sql
SHOW STREAMS;           -- Lister les streams
SHOW TABLES;            -- Lister les tables
SHOW TOPICS;            -- Lister les topics Kafka
SHOW QUERIES;           -- Voir les requ√™tes en cours
DESCRIBE stream_name;   -- Voir le sch√©ma
TERMINATE query_id;     -- Arr√™ter une requ√™te
```

---

## üßπ Nettoyage

```bash
# Arr√™ter les services
make stop

# Nettoyage complet (supprime aussi les volumes)
make clean
```

---

## üìö Fichiers de R√©f√©rence

- **`queries/setup.sql`** - Streams de base cr√©√©s au setup
- **`queries/examples.sql`** - Plus de 20 exemples de requ√™tes ksqlDB
- **`scripts/generate_events.sh`** - Script de g√©n√©ration de donn√©es
- **`scripts/events_data.txt`** - Fichier de donn√©es source (format: user_id|event_type|amount|country)

Consultez `examples.sql` pour plus d'exemples avanc√©s!

---

**Bravo! Vous ma√Ætrisez maintenant ksqlDB et le stream processing SQL! üöÄ**
